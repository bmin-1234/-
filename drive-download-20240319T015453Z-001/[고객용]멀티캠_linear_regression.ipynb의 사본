{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1bbwyQkVxquxMXSCamV9XXWG1IB1Fzy3E","timestamp":1695520787847}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2JcgQKcyKCur"},"source":["# 10차시 실습. 전통적인 선형회귀 코드"]},{"cell_type":"code","metadata":{"id":"kqJ4WSDwKm0K","executionInfo":{"status":"error","timestamp":1695520836304,"user_tz":-540,"elapsed":325,"user":{"displayName":"심심한백수","userId":"14387771983578606102"}},"outputId":"0d9cafed-34d3-4a75-d6ee-bfe8a1303381","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 이하 코드는 아래의 출처를 참고로 하여 작성하였습니다\n","# 출처: scipy 공식 문서(https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html)\n","\n","# import libraries\n","import numpy as np\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","% matplotlib inline\n","\n","# 샘플데이터, 결과는 뭘로 예상됩니까?\n","A = np.array([1,2,3,4,5])\n","B = np.array([1,2,3,4,5])\n","\n","#선형회귀 결과\n","slope, intercept, r_value, p_value, std_err = stats.linregress(A,B)\n","result = stats.linregress(A,B)\n","\n","# 시각화\n","plt.plot(A, B, 'o', label='original data')\n","plt.plot(A, intercept + slope*A, 'r', label='fitted line')\n","plt.legend()\n","plt.show()\n","print(result)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["UsageError: Line magic function `%` not found.\n"]}]},{"cell_type":"markdown","metadata":{"id":"C5P_nIUbRSwB"},"source":["# 11차시 실습. 머신러닝 코드 및 결과 해석 설명"]},{"cell_type":"code","metadata":{"id":"FkzCm4R6PfLl","executionInfo":{"status":"ok","timestamp":1695520845481,"user_tz":-540,"elapsed":5612,"user":{"displayName":"심심한백수","userId":"14387771983578606102"}},"outputId":"43114354-6c43-41d4-9a49-eb05302b3ae0","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 이하 코드는 아래의 출처를 참고로 하여 작성하였습니다\n","# 출처: 모두를 위한 머신러닝(https://hunkim.github.io/ml/)\n","# tensorflow 버전이 업데이트 됨에 따라 tensorflow import 부분 수정 진행하였습니다(2020.05.21)\n","\n","# 기계학습용 라이브러리인 텐서플로를 임포트 합니다.\n","# 무슨말인지 이해 못하셔도 좋습니다\n","# for tensorflow 1.x on tensorflow 2.0\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","\n","\n","\n","# 학습도구 : 예제 데이터\n","X_data = [1, 2, 3, 4, 5]\n","Y_data = [1, 2, 3, 4, 5]\n","\n","\n","\n","# parameter : 기울기(slope)와 Y절편(intercept)\n","A = tf.Variable(tf.random_normal([1]), name='slope')\n","B = tf.Variable(tf.random_normal([1]), name='intercept')\n","\n","\n","\n","# 플레이스 홀더 선언. 지금은 뭔지 몰라도 됩니다\n","X = tf.placeholder(tf.float32, shape=[None])\n","Y = tf.placeholder(tf.float32, shape=[None])\n","\n","\n","\n","# 어떤 모델 만들겁니까? 네 단순선형회귀니까 1차방정식\n","model = X * A + B\n","\n","\n","\n","# 학습을 진행하려면 내가 현재까지 얼마나 틀리고 있는지 알아야 합니다.\n","# 그 틀린정도를 머신러닝에서는 cost(또는 loss) 라고 부릅니다. 이걸 정해줘야 학습을 하죠?\n","# 이 아래 의미는 뭘까요?\n","cost = tf.reduce_mean(tf.square(model - Y))\n","\n","\n","\n","# 틀린정도를 최소화 하도록 합니다. 경사하강 알고리즘을 사용합니다.\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n","train = optimizer.minimize(cost)\n","\n","\n","\n","# 세션을 키고 초기화합니다. 지금은 이게 뭔지 모르셔도 됩니다\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","\n","\n","# 반복문을 돌리기 위해 변수를 선언해 둡니다. 이부분도 여러분들이 지금은 모르셔도 됩니다\n","run_cost = []\n","run_weight = []\n","run_bias = []\n","\n","\n","\n","# 자. 학습을 시켜 보겠습니다.\n","# 아래 range(2001) 이라고 되어있는거 보이시죠? 이게 학습 횟수입니다.\n","# 스스로 최적화 하여 parmeter를 최적화하는걸 보실수 있습니다. 결과가 이해 되시나요?\n","for step in range(2001):\n","  run_cost, run_weight, run_bias, f_data = sess.run([cost, A, B, train], feed_dict={X: X_data, Y: Y_data})\n","  if step % 200 == 0:\n","    print('학습횟수:',' ',step,' ','오차(cost):',run_cost,' ','기울기:', run_weight,' ','Y절편:', run_bias)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]},{"output_type":"stream","name":"stdout","text":["학습횟수:   0   오차(cost): 5.765618   기울기: [0.18090732]   Y절편: [1.0025715]\n","학습횟수:   200   오차(cost): 0.061651062   기울기: [0.83934385]   Y절편: [0.58001983]\n","학습횟수:   400   오차(cost): 0.015907867   기울기: [0.91839194]   Y절편: [0.29463103]\n","학습횟수:   600   오차(cost): 0.004104724   기울기: [0.95854574]   Y절편: [0.14966297]\n","학습횟수:   800   오차(cost): 0.0010591449   기울기: [0.9789426]   Y절편: [0.07602397]\n","학습횟수:   1000   오차(cost): 0.0002732921   기울기: [0.98930347]   Y절편: [0.0386177]\n","학습횟수:   1200   오차(cost): 7.0518094e-05   기울기: [0.99456644]   Y절편: [0.01961659]\n","학습횟수:   1400   오차(cost): 1.8195884e-05   기울기: [0.99724]   Y절편: [0.00996455]\n","학습횟수:   1600   오차(cost): 4.6948708e-06   기울기: [0.998598]   Y절편: [0.00506168]\n","학습횟수:   1800   오차(cost): 1.211484e-06   기울기: [0.9992878]   Y절편: [0.00257126]\n","학습횟수:   2000   오차(cost): 3.1271762e-07   기울기: [0.9996382]   Y절편: [0.0013063]\n"]}]},{"cell_type":"code","metadata":{"id":"X-MxYSjankwc","executionInfo":{"status":"ok","timestamp":1695520848434,"user_tz":-540,"elapsed":353,"user":{"displayName":"심심한백수","userId":"14387771983578606102"}},"outputId":"c8c6e770-40c5-4c50-96d8-899da43fc954","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 예측을 한번 해봅시다\n","# 위 예제 데이터의 관계성에 따르면 X가 10일때 예상되는 Y는 얼마입니까?\n","sess.run(model, feed_dict = {X : [10]})"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([9.997688], dtype=float32)"]},"metadata":{},"execution_count":4}]}]}